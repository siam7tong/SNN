2017-06-28 13:59:57.158600: softmax classifer
2017-06-28 13:59:57.158643: Learning rates LR: 0.100000 
2017-06-28 14:00:13.151465: Iter: 200 [0], loss: 0.156690, acc: 1.00%, avg_loss: 0.769951, avg_acc: 61.00%
2017-06-28 14:00:29.979234: Iter: 400 [0], loss: 0.021030, acc: 1.00%, avg_loss: 0.723793, avg_acc: 66.75%
2017-06-28 14:00:46.467717: Iter: 600 [0], loss: 0.152646, acc: 1.00%, avg_loss: 0.715481, avg_acc: 69.17%
2017-06-28 14:01:02.777867: Iter: 800 [0], loss: 0.012272, acc: 1.00%, avg_loss: 0.666203, avg_acc: 72.00%
2017-06-28 14:01:08.851924: 
Epoch 0: avg_Loss: 0.639546550526, avg_Acc: 73.257142857143
2017-06-28 14:01:19.354518: Iter: 1000 [1], loss: 0.320661, acc: 1.00%, avg_loss: 0.637538, avg_acc: 75.00%
2017-06-28 14:01:35.919195: Iter: 1200 [1], loss: 0.009417, acc: 1.00%, avg_loss: 0.518054, avg_acc: 76.23%
2017-06-28 14:01:52.934446: Iter: 1400 [1], loss: 5.788477, acc: 0.00%, avg_loss: 0.501684, avg_acc: 79.20%
2017-06-28 14:02:09.099915: Iter: 1600 [1], loss: 1.154769, acc: 0.00%, avg_loss: 0.474618, avg_acc: 79.83%
2017-06-28 14:02:21.893204: 
Epoch 1: avg_Loss: 0.494254582670, avg_Acc: 79.200000000000
2017-06-28 14:02:21.893265: Learning rates changed LR: 0.050000 
2017-06-28 14:02:26.083444: Iter: 1800 [2], loss: 0.037719, acc: 1.00%, avg_loss: 0.548141, avg_acc: 81.25%
2017-06-28 14:02:42.348573: Iter: 2000 [2], loss: 0.230558, acc: 1.00%, avg_loss: 0.413144, avg_acc: 84.27%
2017-06-28 14:02:59.188106: Iter: 2200 [2], loss: 0.260093, acc: 1.00%, avg_loss: 0.390362, avg_acc: 86.16%
2017-06-28 14:03:15.845351: Iter: 2400 [2], loss: 0.006990, acc: 1.00%, avg_loss: 0.363192, avg_acc: 86.88%
2017-06-28 14:03:32.127535: Iter: 2600 [2], loss: 0.006205, acc: 1.00%, avg_loss: 0.317385, avg_acc: 88.33%
2017-06-28 14:03:34.338655: 
Epoch 2: avg_Loss: 0.319906837166, avg_Acc: 88.342857142857
2017-06-28 14:03:48.719787: Iter: 2800 [3], loss: 1.934345, acc: 0.00%, avg_loss: 0.332186, avg_acc: 88.37%
2017-06-28 14:04:05.534137: Iter: 3000 [3], loss: 0.016507, acc: 1.00%, avg_loss: 0.313735, avg_acc: 88.98%
2017-06-28 14:04:22.112328: Iter: 3200 [3], loss: 0.944266, acc: 0.00%, avg_loss: 0.351719, avg_acc: 88.81%
2017-06-28 14:04:38.773595: Iter: 3400 [3], loss: 0.000577, acc: 1.00%, avg_loss: 0.337480, avg_acc: 88.60%
2017-06-28 14:04:47.311140: 
Epoch 3: avg_Loss: 0.335478016936, avg_Acc: 88.800000000000
2017-06-28 14:04:47.311203: Learning rates changed LR: 0.025000 
2017-06-28 14:04:55.466124: Iter: 3600 [4], loss: 0.025727, acc: 1.00%, avg_loss: 0.255011, avg_acc: 87.50%
2017-06-28 14:05:12.016847: Iter: 3800 [4], loss: 0.073467, acc: 1.00%, avg_loss: 0.291189, avg_acc: 88.18%
2017-06-28 14:05:28.706914: Iter: 4000 [4], loss: 1.264274, acc: 0.00%, avg_loss: 0.273128, avg_acc: 90.12%
2017-06-28 14:05:45.218063: Iter: 4200 [4], loss: 0.001170, acc: 1.00%, avg_loss: 0.281334, avg_acc: 89.94%
2017-06-28 14:05:59.807858: 
Epoch 4: avg_Loss: 0.278886954777, avg_Acc: 90.057142857143
2017-06-28 14:06:01.759632: Iter: 4400 [5], loss: 0.003104, acc: 1.00%, avg_loss: 0.256183, avg_acc: 90.00%
2017-06-28 14:06:18.115187: Iter: 4600 [5], loss: 0.079298, acc: 1.00%, avg_loss: 0.321490, avg_acc: 86.36%
2017-06-28 14:06:34.391218: Iter: 4800 [5], loss: 0.356220, acc: 1.00%, avg_loss: 0.279618, avg_acc: 88.33%
2017-06-28 14:06:51.281487: Iter: 5000 [5], loss: 0.030868, acc: 1.00%, avg_loss: 0.300957, avg_acc: 87.74%
2017-06-28 14:07:08.332026: Iter: 5200 [5], loss: 0.077385, acc: 1.00%, avg_loss: 0.282996, avg_acc: 88.41%
2017-06-28 14:07:13.141644: 
Epoch 5: avg_Loss: 0.270415941725, avg_Acc: 89.257142857143
2017-06-28 14:07:13.141703: Learning rates changed LR: 0.012500 
2017-06-28 14:07:25.569367: Iter: 5400 [6], loss: 1.569620, acc: 0.00%, avg_loss: 0.248682, avg_acc: 91.67%
2017-06-28 14:07:42.214866: Iter: 5600 [6], loss: 0.000353, acc: 1.00%, avg_loss: 0.271109, avg_acc: 90.99%
2017-06-28 14:07:59.339108: Iter: 5800 [6], loss: 0.009898, acc: 1.00%, avg_loss: 0.249717, avg_acc: 90.99%
2017-06-28 14:08:16.355841: Iter: 6000 [6], loss: 0.019742, acc: 1.00%, avg_loss: 0.239834, avg_acc: 91.26%
2017-06-28 14:08:27.727773: 
Epoch 6: avg_Loss: 0.239201407508, avg_Acc: 91.428571428571
2017-06-28 14:08:33.720145: Iter: 6200 [7], loss: 0.015946, acc: 1.00%, avg_loss: 0.200887, avg_acc: 94.12%
2017-06-28 14:08:50.119665: Iter: 6400 [7], loss: 0.022127, acc: 1.00%, avg_loss: 0.262602, avg_acc: 89.93%
2017-06-28 14:09:06.375714: Iter: 6600 [7], loss: 0.008202, acc: 1.00%, avg_loss: 0.237933, avg_acc: 91.03%
2017-06-28 14:09:22.650029: Iter: 6800 [7], loss: 0.264711, acc: 1.00%, avg_loss: 0.246810, avg_acc: 90.42%
2017-06-28 14:09:39.399934: Iter: 7000 [7], loss: 0.028753, acc: 1.00%, avg_loss: 0.240769, avg_acc: 91.13%
2017-06-28 14:09:40.051728: 
Epoch 7: avg_Loss: 0.239485213606, avg_Acc: 91.314285714286
2017-06-28 14:09:40.051781: Learning rates changed LR: 0.006250 
2017-06-28 14:09:56.098229: Iter: 7200 [8], loss: 0.137980, acc: 1.00%, avg_loss: 0.310795, avg_acc: 90.10%
2017-06-28 14:10:12.288155: Iter: 7400 [8], loss: 2.152107, acc: 0.00%, avg_loss: 0.238243, avg_acc: 92.60%
2017-06-28 14:10:29.050770: Iter: 7600 [8], loss: 0.025697, acc: 1.00%, avg_loss: 0.216536, avg_acc: 92.91%
2017-06-28 14:10:45.510954: Iter: 7800 [8], loss: 0.012242, acc: 1.00%, avg_loss: 0.226548, avg_acc: 92.30%
2017-06-28 14:10:52.610549: 
Epoch 8: avg_Loss: 0.235348551381, avg_Acc: 91.885714285714
2017-06-28 14:11:02.988057: Iter: 8000 [9], loss: 0.002099, acc: 1.00%, avg_loss: 0.199451, avg_acc: 93.97%
2017-06-28 14:11:21.229329: Iter: 8200 [9], loss: 0.043582, acc: 1.00%, avg_loss: 0.274525, avg_acc: 90.51%
2017-06-28 14:11:38.547556: Iter: 8400 [9], loss: 0.029500, acc: 1.00%, avg_loss: 0.241393, avg_acc: 91.67%
2017-06-28 14:11:54.707791: Iter: 8600 [9], loss: 0.015934, acc: 1.00%, avg_loss: 0.234378, avg_acc: 92.18%
2017-06-28 14:12:07.944276: 
Epoch 9: avg_Loss: 0.234859993993, avg_Acc: 92.228571428571
2017-06-28 14:12:07.944335: Learning rates changed LR: 0.003125 
2017-06-28 14:12:11.677522: Iter: 8800 [10], loss: 0.438471, acc: 1.00%, avg_loss: 0.303285, avg_acc: 90.00%
2017-06-28 14:12:30.115306: Iter: 9000 [10], loss: 0.001092, acc: 1.00%, avg_loss: 0.223321, avg_acc: 92.50%
2017-06-28 14:12:47.508676: Iter: 9200 [10], loss: 0.021639, acc: 1.00%, avg_loss: 0.219476, avg_acc: 92.50%
2017-06-28 14:13:03.965890: Iter: 9400 [10], loss: 0.285595, acc: 1.00%, avg_loss: 0.222703, avg_acc: 92.19%
2017-06-28 14:13:20.730983: Iter: 9600 [10], loss: 0.018357, acc: 1.00%, avg_loss: 0.226404, avg_acc: 91.90%
2017-06-28 14:13:23.676034: 
Epoch 10: avg_Loss: 0.228399914958, avg_Acc: 91.885714285714
2017-06-28 14:13:37.119595: Iter: 9800 [11], loss: 0.050191, acc: 1.00%, avg_loss: 0.246615, avg_acc: 89.63%
2017-06-28 14:13:53.566503: Iter: 10000 [11], loss: 0.014922, acc: 1.00%, avg_loss: 0.202739, avg_acc: 92.58%
2017-06-28 14:14:10.079120: Iter: 10200 [11], loss: 0.567550, acc: 1.00%, avg_loss: 0.199304, avg_acc: 92.91%
2017-06-28 14:14:26.715605: Iter: 10400 [11], loss: 0.038525, acc: 1.00%, avg_loss: 0.216540, avg_acc: 92.41%
2017-06-28 14:14:36.295161: 
Epoch 11: avg_Loss: 0.226406526103, avg_Acc: 92.000000000000
2017-06-28 14:14:36.295221: Learning rates changed LR: 0.001563 
2017-06-28 14:14:44.584596: Iter: 10600 [12], loss: 0.040541, acc: 1.00%, avg_loss: 0.275675, avg_acc: 93.18%
2017-06-28 14:15:02.690483: Iter: 10800 [12], loss: 0.007481, acc: 1.00%, avg_loss: 0.268340, avg_acc: 92.71%
2017-06-28 14:15:19.968741: Iter: 11000 [12], loss: 0.015871, acc: 1.00%, avg_loss: 0.245210, avg_acc: 92.42%
2017-06-28 14:15:37.058402: Iter: 11200 [12], loss: 0.489906, acc: 1.00%, avg_loss: 0.216397, avg_acc: 93.02%
2017-06-28 14:15:53.013366: 
Epoch 12: avg_Loss: 0.227702496528, avg_Acc: 92.342857142857
2017-06-28 14:15:54.259774: Iter: 11400 [13], loss: 0.086379, acc: 1.00%, avg_loss: 0.058936, avg_acc: 100.00%
2017-06-28 14:16:10.710628: Iter: 11600 [13], loss: 0.014795, acc: 1.00%, avg_loss: 0.245945, avg_acc: 91.98%
2017-06-28 14:16:27.404603: Iter: 11800 [13], loss: 0.040654, acc: 1.00%, avg_loss: 0.217119, avg_acc: 92.96%
2017-06-28 14:16:44.433756: Iter: 12000 [13], loss: 0.003389, acc: 1.00%, avg_loss: 0.218650, avg_acc: 92.97%
2017-06-28 14:17:01.419588: Iter: 12200 [13], loss: 0.193798, acc: 1.00%, avg_loss: 0.227286, avg_acc: 92.12%
2017-06-28 14:17:06.805651: 
Epoch 13: avg_Loss: 0.226697326263, avg_Acc: 92.228571428571
2017-06-28 14:17:06.805712: Learning rates changed LR: 0.000781 
2017-06-28 14:17:18.446123: Iter: 12400 [14], loss: 0.023982, acc: 1.00%, avg_loss: 0.200161, avg_acc: 91.91%
2017-06-28 14:17:34.681310: Iter: 12600 [14], loss: 0.123110, acc: 1.00%, avg_loss: 0.213121, avg_acc: 92.26%
2017-06-28 14:17:50.902192: Iter: 12800 [14], loss: 0.123492, acc: 1.00%, avg_loss: 0.216817, avg_acc: 92.16%
2017-06-28 14:18:07.216122: Iter: 13000 [14], loss: 0.090447, acc: 1.00%, avg_loss: 0.227216, avg_acc: 91.85%
2017-06-28 14:18:18.876840: 
Epoch 14: avg_Loss: 0.225724260128, avg_Acc: 92.114285714286
2017-06-28 14:18:19.168955: 
Testing at last epoch...
2017-06-28 14:19:21.622704: epoch: 15 Accuracy: 92.3308%, loss: 0.204967343013, i: 665
2017-06-28 14:19:21.622752: Exiting train...
