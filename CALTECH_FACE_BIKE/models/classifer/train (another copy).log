2017-06-28 14:40:59.181721: softmax classifer
2017-06-28 14:40:59.181765: Learning rates LR: 0.100000 
2017-06-28 14:41:19.400114: Iter: 200 [0], loss: 0.156690, acc: 1.00%, avg_loss: 0.769951, avg_acc: 61.00%
2017-06-28 14:41:42.368977: Iter: 400 [0], loss: 0.021030, acc: 1.00%, avg_loss: 0.723793, avg_acc: 66.75%
2017-06-28 14:42:09.163968: Iter: 600 [0], loss: 0.152646, acc: 1.00%, avg_loss: 0.715481, avg_acc: 69.17%
2017-06-28 14:42:36.195054: Iter: 800 [0], loss: 0.012272, acc: 1.00%, avg_loss: 0.666203, avg_acc: 72.00%
2017-06-28 14:42:46.480257: 
Epoch 0: avg_Loss: 0.639546550526, avg_Acc: 73.257142857143
2017-06-28 14:43:03.502840: Iter: 1000 [1], loss: 0.320661, acc: 1.00%, avg_loss: 0.637538, avg_acc: 75.00%
2017-06-28 14:43:30.284028: Iter: 1200 [1], loss: 0.009417, acc: 1.00%, avg_loss: 0.518054, avg_acc: 76.23%
2017-06-28 14:43:56.989961: Iter: 1400 [1], loss: 5.788477, acc: 0.00%, avg_loss: 0.501684, avg_acc: 79.20%
2017-06-28 14:44:23.671087: Iter: 1600 [1], loss: 1.154769, acc: 0.00%, avg_loss: 0.474618, avg_acc: 79.83%
2017-06-28 14:44:40.919417: 
Epoch 1: avg_Loss: 0.494254582670, avg_Acc: 79.200000000000
2017-06-28 14:44:45.450459: Iter: 1800 [2], loss: 0.301304, acc: 1.00%, avg_loss: 0.537227, avg_acc: 81.25%
2017-06-28 14:45:11.916967: Iter: 2000 [2], loss: 0.206498, acc: 1.00%, avg_loss: 0.525391, avg_acc: 83.47%
2017-06-28 14:45:46.532633: Iter: 2200 [2], loss: 0.164115, acc: 1.00%, avg_loss: 0.493292, avg_acc: 85.04%
2017-06-28 14:46:11.721847: Iter: 2400 [2], loss: 0.005799, acc: 1.00%, avg_loss: 0.469868, avg_acc: 85.19%
2017-06-28 14:46:29.009976: Iter: 2600 [2], loss: 0.002079, acc: 1.00%, avg_loss: 0.409431, avg_acc: 86.56%
2017-06-28 14:46:31.421806: 
Epoch 2: avg_Loss: 0.410777609806, avg_Acc: 86.514285714286
2017-06-28 14:46:31.421860: Learning rates changed LR: 0.066667 
2017-06-28 14:46:46.644871: Iter: 2800 [3], loss: 2.977334, acc: 0.00%, avg_loss: 0.369316, avg_acc: 86.05%
2017-06-28 14:47:03.732049: Iter: 3000 [3], loss: 0.028665, acc: 1.00%, avg_loss: 0.354455, avg_acc: 87.63%
2017-06-28 14:47:20.469616: Iter: 3200 [3], loss: 0.640306, acc: 1.00%, avg_loss: 0.392218, avg_acc: 87.24%
2017-06-28 14:47:36.758642: Iter: 3400 [3], loss: 0.000119, acc: 1.00%, avg_loss: 0.380775, avg_acc: 86.53%
2017-06-28 14:47:45.216923: 
Epoch 3: avg_Loss: 0.376598494782, avg_Acc: 86.971428571429
2017-06-28 14:47:53.266455: Iter: 3600 [4], loss: 0.085776, acc: 1.00%, avg_loss: 0.291092, avg_acc: 86.46%
2017-06-28 14:48:09.635508: Iter: 3800 [4], loss: 0.427925, acc: 1.00%, avg_loss: 0.377524, avg_acc: 86.82%
2017-06-28 14:48:26.567808: Iter: 4000 [4], loss: 2.709998, acc: 0.00%, avg_loss: 0.362183, avg_acc: 86.90%
2017-06-28 14:48:43.867044: Iter: 4200 [4], loss: 0.006846, acc: 1.00%, avg_loss: 0.364576, avg_acc: 87.50%
2017-06-28 14:48:58.737789: 
Epoch 4: avg_Loss: 0.361980050599, avg_Acc: 87.314285714286
2017-06-28 14:49:00.750221: Iter: 4400 [5], loss: 0.000300, acc: 1.00%, avg_loss: 0.172782, avg_acc: 95.00%
2017-06-28 14:49:17.248337: Iter: 4600 [5], loss: 0.056303, acc: 1.00%, avg_loss: 0.392226, avg_acc: 85.91%
2017-06-28 14:49:33.819743: Iter: 4800 [5], loss: 0.209624, acc: 1.00%, avg_loss: 0.354568, avg_acc: 87.62%
2017-06-28 14:49:50.850268: Iter: 5000 [5], loss: 0.551755, acc: 1.00%, avg_loss: 0.366284, avg_acc: 87.10%
2017-06-28 14:50:07.971809: Iter: 5200 [5], loss: 0.088098, acc: 1.00%, avg_loss: 0.342830, avg_acc: 87.32%
2017-06-28 14:50:12.844378: 
Epoch 5: avg_Loss: 0.326671475540, avg_Acc: 88.114285714286
2017-06-28 14:50:25.101076: Iter: 5400 [6], loss: 2.058495, acc: 0.00%, avg_loss: 0.304795, avg_acc: 87.50%
2017-06-28 14:50:41.657853: Iter: 5600 [6], loss: 0.000106, acc: 1.00%, avg_loss: 0.365853, avg_acc: 88.08%
2017-06-28 14:50:58.688994: Iter: 5800 [6], loss: 0.009988, acc: 1.00%, avg_loss: 0.337403, avg_acc: 88.05%
2017-06-28 14:51:15.889706: Iter: 6000 [6], loss: 0.006209, acc: 1.00%, avg_loss: 0.316451, avg_acc: 89.38%
2017-06-28 14:51:27.630411: 
Epoch 6: avg_Loss: 0.315962519613, avg_Acc: 89.600000000000
2017-06-28 14:51:33.684189: Iter: 6200 [7], loss: 0.005761, acc: 1.00%, avg_loss: 0.243342, avg_acc: 86.76%
2017-06-28 14:51:50.596188: Iter: 6400 [7], loss: 0.004115, acc: 1.00%, avg_loss: 0.419099, avg_acc: 83.96%
2017-06-28 14:52:08.914091: Iter: 6600 [7], loss: 0.001315, acc: 1.00%, avg_loss: 0.350360, avg_acc: 86.75%
2017-06-28 14:52:32.027463: Iter: 6800 [7], loss: 0.114542, acc: 1.00%, avg_loss: 0.352927, avg_acc: 87.72%
2017-06-28 14:52:55.085688: Iter: 7000 [7], loss: 0.036532, acc: 1.00%, avg_loss: 0.330615, avg_acc: 88.36%
2017-06-28 14:52:55.891547: 
Epoch 7: avg_Loss: 0.329728261126, avg_Acc: 88.457142857143
2017-06-28 14:52:55.891625: Learning rates changed LR: 0.044444 
2017-06-28 14:53:15.436160: Iter: 7200 [8], loss: 0.021603, acc: 1.00%, avg_loss: 0.372806, avg_acc: 87.50%
2017-06-28 14:53:34.838712: Iter: 7400 [8], loss: 1.377846, acc: 0.00%, avg_loss: 0.281634, avg_acc: 90.05%
2017-06-28 14:53:54.425611: Iter: 7600 [8], loss: 0.057576, acc: 1.00%, avg_loss: 0.263131, avg_acc: 90.37%
2017-06-28 14:54:13.940768: Iter: 7800 [8], loss: 0.000439, acc: 1.00%, avg_loss: 0.281085, avg_acc: 89.65%
2017-06-28 14:54:22.302205: 
Epoch 8: avg_Loss: 0.296476851187, avg_Acc: 89.714285714286
2017-06-28 14:54:34.367391: Iter: 8000 [9], loss: 0.000182, acc: 1.00%, avg_loss: 0.246465, avg_acc: 93.10%
2017-06-28 14:54:54.062340: Iter: 8200 [9], loss: 0.517974, acc: 1.00%, avg_loss: 0.403438, avg_acc: 86.08%
2017-06-28 14:55:14.272657: Iter: 8400 [9], loss: 0.011396, acc: 1.00%, avg_loss: 0.341160, avg_acc: 88.18%
2017-06-28 14:55:33.890559: Iter: 8600 [9], loss: 0.024937, acc: 1.00%, avg_loss: 0.308597, avg_acc: 89.39%
2017-06-28 14:55:49.860469: 
Epoch 9: avg_Loss: 0.308829682099, avg_Acc: 89.600000000000
2017-06-28 14:55:54.172887: Iter: 8800 [10], loss: 0.130500, acc: 1.00%, avg_loss: 0.379663, avg_acc: 90.00%
2017-06-28 14:56:13.561825: Iter: 9000 [10], loss: 0.000041, acc: 1.00%, avg_loss: 0.250568, avg_acc: 93.33%
2017-06-28 14:56:33.410893: Iter: 9200 [10], loss: 0.018377, acc: 1.00%, avg_loss: 0.235284, avg_acc: 92.50%
2017-06-28 14:56:53.144093: Iter: 9400 [10], loss: 0.345553, acc: 1.00%, avg_loss: 0.259503, avg_acc: 91.88%
2017-06-28 14:57:12.758014: Iter: 9600 [10], loss: 0.000646, acc: 1.00%, avg_loss: 0.272151, avg_acc: 91.31%
2017-06-28 14:57:16.210276: 
Epoch 10: avg_Loss: 0.278489947419, avg_Acc: 91.200000000000
2017-06-28 14:57:32.392775: Iter: 9800 [11], loss: 0.015471, acc: 1.00%, avg_loss: 0.274489, avg_acc: 90.85%
2017-06-28 14:57:51.897621: Iter: 10000 [11], loss: 0.000720, acc: 1.00%, avg_loss: 0.221360, avg_acc: 92.31%
2017-06-28 14:58:11.386269: Iter: 10200 [11], loss: 0.170099, acc: 1.00%, avg_loss: 0.234295, avg_acc: 91.13%
2017-06-28 14:58:30.890755: Iter: 10400 [11], loss: 0.002221, acc: 1.00%, avg_loss: 0.252585, avg_acc: 90.58%
2017-06-28 14:58:42.010764: 
Epoch 11: avg_Loss: 0.268420400904, avg_Acc: 89.942857142857
2017-06-28 14:58:42.010833: Learning rates changed LR: 0.029630 
2017-06-28 14:58:51.156284: Iter: 10600 [12], loss: 0.019659, acc: 1.00%, avg_loss: 0.301108, avg_acc: 90.91%
2017-06-28 14:59:10.996675: Iter: 10800 [12], loss: 0.000906, acc: 1.00%, avg_loss: 0.295153, avg_acc: 89.93%
2017-06-28 14:59:30.964697: Iter: 11000 [12], loss: 0.015314, acc: 1.00%, avg_loss: 0.274097, avg_acc: 90.16%
2017-06-28 14:59:51.128542: Iter: 11200 [12], loss: 0.775872, acc: 0.00%, avg_loss: 0.232871, avg_acc: 91.57%
2017-06-28 15:00:10.243456: 
Epoch 12: avg_Loss: 0.238880296515, avg_Acc: 90.742857142857
2017-06-28 15:00:11.784785: Iter: 11400 [13], loss: 0.002021, acc: 1.00%, avg_loss: 0.090052, avg_acc: 91.67%
2017-06-28 15:00:32.225847: Iter: 11600 [13], loss: 0.002182, acc: 1.00%, avg_loss: 0.286363, avg_acc: 90.57%
2017-06-28 15:00:52.330454: Iter: 11800 [13], loss: 0.030082, acc: 1.00%, avg_loss: 0.242351, avg_acc: 90.78%
2017-06-28 15:01:12.602708: Iter: 12000 [13], loss: 0.002952, acc: 1.00%, avg_loss: 0.238184, avg_acc: 91.18%
2017-06-28 15:01:32.766216: Iter: 12200 [13], loss: 0.107667, acc: 1.00%, avg_loss: 0.246962, avg_acc: 90.89%
2017-06-28 15:01:39.412592: 
Epoch 13: avg_Loss: 0.244405414094, avg_Acc: 91.085714285714
2017-06-28 15:01:39.412670: Learning rates changed LR: 0.019753 
2017-06-28 15:01:53.749181: Iter: 12400 [14], loss: 0.010545, acc: 1.00%, avg_loss: 0.189699, avg_acc: 94.12%
2017-06-28 15:02:13.731250: Iter: 12600 [14], loss: 0.243954, acc: 1.00%, avg_loss: 0.218093, avg_acc: 91.96%
2017-06-28 15:02:34.459447: Iter: 12800 [14], loss: 0.106329, acc: 1.00%, avg_loss: 0.220260, avg_acc: 92.16%
2017-06-28 15:02:54.466927: Iter: 13000 [14], loss: 0.033594, acc: 1.00%, avg_loss: 0.230614, avg_acc: 91.98%
2017-06-28 15:03:08.612722: 
Epoch 14: avg_Loss: 0.229045273927, avg_Acc: 92.342857142857
2017-06-28 15:03:08.928016: 
Testing at last epoch...
2017-06-28 15:04:15.420551: epoch: 15 Accuracy: 92.6316%, loss: 0.198321002168, i: 665
2017-06-28 15:04:15.420603: Exiting train...
