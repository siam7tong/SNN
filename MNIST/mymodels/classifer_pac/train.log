2017-12-29 12:40:15.591011: softmax classifer
2017-12-29 12:40:15.591104: Learning rates LR: 0.000010 
2017-12-29 12:42:10.038538: Iter: 2000 [0], loss: 0.000000, acc: 1.00%, avg_loss: 13452.938150, avg_acc: 77.20%
2017-12-29 12:44:16.712091: Iter: 4000 [0], loss: 0.000000, acc: 1.00%, avg_loss: 13223.840516, avg_acc: 76.90%
2017-12-29 12:46:22.701644: Iter: 6000 [0], loss: 0.000000, acc: 1.00%, avg_loss: 13384.238592, avg_acc: 76.77%
2017-12-29 12:48:28.529751: Iter: 8000 [0], loss: 0.000000, acc: 1.00%, avg_loss: 13396.676847, avg_acc: 76.75%
2017-12-29 12:50:35.093741: Iter: 10000 [0], loss: 48003.468750, acc: 0.00%, avg_loss: 13403.937067, avg_acc: 76.78%
2017-12-29 12:52:40.674612: Iter: 12000 [0], loss: 42006.210938, acc: 0.00%, avg_loss: 13254.542598, avg_acc: 76.98%
2017-12-29 12:52:40.674909: 
Epoch 0: avg_Loss: 13255.647235137352, avg_Acc: 76.981415117927
2017-12-29 12:52:40.674987: Learning rates changed LR: 0.000010 
2017-12-29 12:54:48.478519: Iter: 14000 [1], loss: 0.000000, acc: 1.00%, avg_loss: 12269.508728, avg_acc: 77.65%
2017-12-29 12:56:54.792325: Iter: 16000 [1], loss: 12929.125000, acc: 0.00%, avg_loss: 12781.156170, avg_acc: 77.68%
2017-12-29 12:59:01.851799: Iter: 18000 [1], loss: 5202.414062, acc: 0.00%, avg_loss: 12529.681765, avg_acc: 77.72%
2017-12-29 13:01:08.806931: Iter: 20000 [1], loss: 111253.953125, acc: 0.00%, avg_loss: 12912.834228, avg_acc: 77.53%
2017-12-29 13:03:15.834046: Iter: 22000 [1], loss: 0.000000, acc: 1.00%, avg_loss: 12798.482005, avg_acc: 77.50%
2017-12-29 13:05:20.591987: Iter: 24000 [1], loss: 0.000000, acc: 1.00%, avg_loss: 13254.241094, avg_acc: 76.98%
2017-12-29 13:05:20.592531: 
Epoch 1: avg_Loss: 13255.345706402575, avg_Acc: 76.981415117927
2017-12-29 13:05:20.592591: Learning rates changed LR: 0.000010 
2017-12-29 13:07:25.893119: Iter: 26000 [2], loss: 0.000000, acc: 1.00%, avg_loss: 13722.367383, avg_acc: 77.40%
2017-12-29 13:09:31.526855: Iter: 28000 [2], loss: 0.000000, acc: 1.00%, avg_loss: 13280.079025, avg_acc: 77.83%
2017-12-29 13:11:38.311154: Iter: 30000 [2], loss: 0.000000, acc: 1.00%, avg_loss: 13219.366419, avg_acc: 77.38%
2017-12-29 13:13:45.602172: Iter: 32000 [2], loss: 0.000000, acc: 1.00%, avg_loss: 13165.509703, avg_acc: 77.26%
2017-12-29 13:15:52.133066: Iter: 34000 [2], loss: 0.000000, acc: 1.00%, avg_loss: 13218.637687, avg_acc: 77.23%
2017-12-29 13:17:55.467046: Iter: 36000 [2], loss: 0.000000, acc: 1.00%, avg_loss: 13253.968057, avg_acc: 76.98%
2017-12-29 13:17:55.467300: 
Epoch 2: avg_Loss: 13255.072646353341, avg_Acc: 76.989749145762
2017-12-29 13:17:55.467344: Learning rates changed LR: 0.000010 
2017-12-29 13:20:02.460390: Iter: 38000 [3], loss: 0.000000, acc: 1.00%, avg_loss: 12366.348858, avg_acc: 77.95%
2017-12-29 13:22:08.663107: Iter: 40000 [3], loss: 0.000000, acc: 1.00%, avg_loss: 13092.109076, avg_acc: 77.40%
2017-12-29 13:24:14.381782: Iter: 42000 [3], loss: 0.000000, acc: 1.00%, avg_loss: 12969.476600, avg_acc: 77.53%
2017-12-29 13:26:19.284012: Iter: 44000 [3], loss: 0.000000, acc: 1.00%, avg_loss: 13181.546597, avg_acc: 77.05%
2017-12-29 13:28:25.817503: Iter: 46000 [3], loss: 0.000000, acc: 1.00%, avg_loss: 13098.490057, avg_acc: 77.15%
2017-12-29 13:30:32.068649: Iter: 48000 [3], loss: 0.000000, acc: 1.00%, avg_loss: 13253.667583, avg_acc: 76.98%
2017-12-29 13:30:32.069055: 
Epoch 3: avg_Loss: 13254.772147190652, avg_Acc: 76.989749145762
2017-12-29 13:30:32.069205: Learning rates changed LR: 0.000010 
2017-12-29 13:32:39.462755: Iter: 50000 [4], loss: 0.000000, acc: 1.00%, avg_loss: 12796.090996, avg_acc: 77.65%
2017-12-29 13:34:46.776699: Iter: 52000 [4], loss: 20789.601562, acc: 0.00%, avg_loss: 13269.886437, avg_acc: 76.65%
2017-12-29 13:36:50.648710: Iter: 54000 [4], loss: 0.000000, acc: 1.00%, avg_loss: 12982.355047, avg_acc: 77.00%
2017-12-29 13:38:55.650424: Iter: 56000 [4], loss: 0.000000, acc: 1.00%, avg_loss: 13198.159097, avg_acc: 76.98%
2017-12-29 13:41:01.880961: Iter: 58000 [4], loss: 49239.453125, acc: 0.00%, avg_loss: 12909.344363, avg_acc: 77.28%
2017-12-29 13:43:06.846303: Iter: 60000 [4], loss: 0.000000,