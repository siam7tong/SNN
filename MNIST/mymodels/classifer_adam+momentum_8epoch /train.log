2017-12-28 21:50:06.887770: softmax classifer
2017-12-28 21:50:06.887830: Learning rates LR: 1.000000 
2017-12-28 21:51:30.690196: Iter: 2000 [0], loss: 183.312012, acc: 0.00%, avg_loss: 1833.050095, avg_acc: 27.55%
2017-12-28 21:52:58.438675: Iter: 4000 [0], loss: 388.968750, acc: 0.00%, avg_loss: 1772.407948, avg_acc: 32.92%
2017-12-28 21:54:39.526180: Iter: 6000 [0], loss: 0.000000, acc: 1.00%, avg_loss: 1805.859001, avg_acc: 35.45%
2017-12-28 21:55:56.788690: Iter: 8000 [0], loss: 0.000000, acc: 1.00%, avg_loss: 1776.048453, avg_acc: 37.90%
2017-12-28 21:57:14.693754: Iter: 10000 [0], loss: 691.010742, acc: 0.00%, avg_loss: 1781.357127, avg_acc: 39.79%
2017-12-28 21:58:34.023682: Iter: 12000 [0], loss: 0.000000, acc: 1.00%, avg_loss: 1765.419370, avg_acc: 41.25%
2017-12-28 21:58:34.023909: 
Epoch 0: avg_Loss: 1765.566500083150, avg_Acc: 41.253437786482
2017-12-28 21:58:34.023949: Learning rates changed LR: 0.100000 
2017-12-28 21:59:56.867684: Iter: 14000 [1], loss: 0.000000, acc: 1.00%, avg_loss: 503.911068, avg_acc: 68.85%
2017-12-28 22:01:13.797055: Iter: 16000 [1], loss: 0.000000, acc: 1.00%, avg_loss: 441.572620, avg_acc: 70.70%
2017-12-28 22:02:31.215479: Iter: 18000 [1], loss: 579.748535, acc: 0.00%, avg_loss: 436.806746, avg_acc: 70.53%
2017-12-28 22:03:48.709258: Iter: 20000 [1], loss: 0.000000, acc: 1.00%, avg_loss: 429.316929, avg_acc: 70.74%
2017-12-28 22:05:11.317685: Iter: 22000 [1], loss: 0.000000, acc: 1.00%, avg_loss: 429.348442, avg_acc: 70.73%
2017-12-28 22:06:33.455439: Iter: 24000 [1], loss: 2290.727539, acc: 0.00%, avg_loss: 424.568002, avg_acc: 70.78%
2017-12-28 22:06:33.455637: 
Epoch 1: avg_Loss: 424.603385309971, avg_Acc: 70.789232436036
2017-12-28 22:06:33.455691: Learning rates changed LR: 0.100000 
2017-12-28 22:07:53.408226: Iter: 26000 [2], loss: 0.000000, acc: 1.00%, avg_loss: 382.343249, avg_acc: 73.30%
2017-12-28 22:09:14.493048: Iter: 28000 [2], loss: 873.928223, acc: 0.00%, avg_loss: 373.699938, avg_acc: 73.22%
2017-12-28 22:10:33.427441: Iter: 30000 [2], loss: 0.000000, acc: 1.00%, avg_loss: 373.545963, avg_acc: 72.43%
2017-12-28 22:11:52.014802: Iter: 32000 [2], loss: 0.000000, acc: 1.00%, avg_loss: 367.106792, avg_acc: 72.00%
2017-12-28 22:13:12.601621: Iter: 34000 [2], loss: 0.000000, acc: 1.00%, avg_loss: 371.892894, avg_acc: 71.95%
2017-12-28 22:14:31.157659: Iter: 36000 [2], loss: 0.000000, acc: 1.00%, avg_loss: 367.777543, avg_acc: 71.87%
2017-12-28 22:14:31.157863: 
Epoch 2: avg_Loss: 367.808193277862, avg_Acc: 71.872656054671
2017-12-28 22:14:31.157910: Learning rates changed LR: 0.010000 
2017-12-28 22:15:51.656301: Iter: 38000 [3], loss: 0.000000, acc: 1.00%, avg_loss: 256.806111, avg_acc: 76.55%
2017-12-28 22:17:16.545458: Iter: 40000 [3], loss: 0.000000, acc: 1.00%, avg_loss: 253.101353, avg_acc: 76.90%
2017-12-28 22:18:41.950932: Iter: 42000 [3], loss: 0.000000, acc: 1.00%, avg_loss: 271.403878, avg_acc: 76.62%
2017-12-28 22:20:08.482569: Iter: 44000 [3], loss: 339.109375, acc: 0.00%, avg_loss: 273.402866, avg_acc: 76.46%
2017-12-28 22:21:28.694546: Iter: 46000 [3], loss: 2016.235352, acc: 0.00%, avg_loss: 273.323293, avg_acc: 76.38%
2017-12-28 22:22:47.802196: Iter: 48000 [3], loss: 0.000000, acc: 1.00%, avg_loss: 267.282106, avg_acc: 76.43%
2017-12-28 22:22:47.802515: 
Epoch 3: avg_Loss: 267.304381749176, avg_Acc: 76.439703308609
2017-12-28 22:22:47.802604: Learning rates changed LR: 0.001000 
2017-12-28 22:22:48.670860: 
Testing at last epoch...
2017-12-28 22:29:37.343028: epoch: 4 Accuracy: 77.5600%, loss: 245.308637587123, i: 10000
2017-12-28 22:29:37.343143: Exiting train...
