2017-12-20 19:07:34.185421: softmax classifer
2017-12-20 19:07:34.185493: Learning rates LR: 100.000000 
2017-12-20 19:08:52.336795: Iter: 2000 [0], loss: 23008220.000000, acc: 0.00%, avg_loss: 12714100.320046, avg_acc: 24.45%
2017-12-20 19:10:31.151067: Iter: 4000 [0], loss: 0.000000, acc: 1.00%, avg_loss: 11817878.380711, avg_acc: 30.23%
2017-12-20 19:11:51.623833: Iter: 6000 [0], loss: 7212204.000000, acc: 0.00%, avg_loss: 11297205.704307, avg_acc: 34.22%
2017-12-20 19:13:38.349254: Iter: 8000 [0], loss: 0.000000, acc: 1.00%, avg_loss: 10844164.997543, avg_acc: 37.16%
2017-12-20 19:15:27.105096: Iter: 10000 [0], loss: 0.000000, acc: 1.00%, avg_loss: 10559924.012684, avg_acc: 39.51%
2017-12-20 19:17:05.018381: Iter: 12000 [0], loss: 0.000000, acc: 1.00%, avg_loss: 10301114.681695, avg_acc: 41.42%
2017-12-20 19:18:28.262237: Iter: 14000 [0], loss: 0.000000, acc: 1.00%, avg_loss: 9954815.142632, avg_acc: 43.11%
2017-12-20 19:19:48.387498: Iter: 16000 [0], loss: 39001120.000000, acc: 0.00%, avg_loss: 9782301.146209, avg_acc: 44.29%
2017-12-20 19:21:29.365798: Iter: 18000 [0], loss: 16308129.000000, acc: 0.00%, avg_loss: 9611874.346936, avg_acc: 45.37%
2017-12-20 19:22:47.843776: Iter: 20000 [0], loss: 28299562.000000, acc: 0.00%, avg_loss: 9431768.487667, avg_acc: 46.37%
2017-12-20 19:24:07.942715: Iter: 22000 [0], loss: 0.000000, acc: 1.00%, avg_loss: 9312658.645879, avg_acc: 47.21%
2017-12-20 19:25:26.436532: Iter: 24000 [0], loss: 0.000000, acc: 1.00%, avg_loss: 9272245.350139, avg_acc: 47.75%
2017-12-20 19:26:44.630313: Iter: 26000 [0], loss: 66835364.000000, acc: 0.00%, avg_loss: 9186321.692648, avg_acc: 48.43%
2017-12-20 19:28:21.361598: Iter: 28000 [0], loss: 0.000000, acc: 1.00%, avg_loss: 9049321.665834, avg_acc: 49.21%
2017-12-20 19:29:39.860394: Iter: 30000 [0], loss: 0.000000, acc: 1.00%, avg_loss: 8965117.890978, avg_acc: 49.84%
2017-12-20 19:30:56.969259: Iter: 32000 [0], loss: 0.000000, acc: 1.00%, avg_loss: 8902156.064073, avg_acc: 50.34%
2017-12-20 19:32:15.354994: Iter: 34000 [0], loss: 0.000000, acc: 1.00%, avg_loss: 8883199.925039, avg_acc: 50.77%
2017-12-20 19:33:32.561447: Iter: 36000 [0], loss: 0.000000, acc: 1.00%, avg_loss: 8787611.965010, avg_acc: 51.34%
2017-12-20 19:34:52.428510: Iter: 38000 [0], loss: 0.000000, acc: 1.00%, avg_loss: 8742181.473075, avg_acc: 51.70%
2017-12-20 19:36:10.733742: Iter: 40000 [0], loss: 0.000000, acc: 1.00%, avg_loss: 8670768.552534, avg_acc: 52.17%
2017-12-20 19:37:31.301249: Iter: 42000 [0], loss: 37837432.000000, acc: 0.00%, avg_loss: 8639350.683532, avg_acc: 52.50%
2017-12-20 19:38:49.782158: Iter: 44000 [0], loss: 0.000000, acc: 1.00%, avg_loss: 8582226.218212, avg_acc: 52.89%
2017-12-20 19:40:21.483538: Iter: 46000 [0], loss: 0.000000, acc: 1.00%, avg_loss: 8530296.572301, avg_acc: 53.20%
2017-12-20 19:41:51.566018: Iter: 48000 [0], loss: 14577810.000000, acc: 0.00%, avg_loss: 8465881.861736, avg_acc: 53.56%
2017-12-20 19:43:24.901880: Iter: 50000 [0], loss: 0.000000, acc: 1.00%, avg_loss: 8426506.705617, avg_acc: 53.84%
2017-12-20 19:44:44.124338: Iter: 52000 [0], loss: 1924246.000000, acc: 0.00%, avg_loss: 8403168.362564, avg_acc: 54.05%
2017-12-20 19:46:12.225513: Iter: 54000 [0], loss: 0.000000, acc: 1.00%, avg_loss: 8341019.915479, avg_acc: 54.41%
2017-12-20 19:46:12.227444: 
Epoch 0: avg_Loss: 8341174.381670815870, avg_Acc: 54.410266856794
2017-12-20 19:46:12.227746: Learning rates changed LR: 30.000000 
2017-12-20 19:47:59.915406: Iter: 56000 [1], loss: 0.000000, acc: 1.00%, avg_loss: 3475936.654000, avg_acc: 72.65%
2017-12-20 19:49:25.999721: Iter: 58000 [1], loss: 0.000000, acc: 1.00%, avg_loss: 3562255.826250, avg_acc: 72.35%
2017-12-20 19:50:58.270982: Iter: 60000 [1], loss: 0.000000, acc: 1.00%, avg_loss: 3425639.504583, avg_acc: 72.47%
2017-12-20 19:52:19.060446: Iter: 62000 [1], loss: 0.000000, acc: 1.00%, avg_loss: 3456754.285312, avg_acc: 72.55%
2017-12-20 19:53:57.580017: Iter: 64000 [1], loss: 4390084.000000, acc: 0.00%, avg_loss: 3400059.022450, avg_acc: 72.90%
2017-12-20 19:55:15.943095: Iter: 66000 [1], loss: 0.000000, acc: 1.00%, avg_loss: 3371805.144917, avg_acc: 72.88%
2017-12-20 19:56:33.599981: Iter: 68000 [1], loss: 17124078.000000, acc: 0.00%, avg_loss: 3394690.680643, avg_acc: 72.66%
2017-12-20 19:57:51.048467: Iter: 70000 [1], loss: 0.000000, acc: 1.00%, avg_loss: 3375017.214156, avg_acc: 72.69%
2017-12-20 19:59:08.421912: Iter: 72000 [1], loss: 0.000000, acc: 1.00%, avg_loss: 3341348.027806, avg_acc: 72.80%
2017-12-20 20:00:25.868339: Iter: 74000 [1], loss: 0.000000, acc: 1.00%, avg_loss: 3313504.962950, avg_acc: 73.06%
2017-12-20 20:01:43.371672: Iter: 76000 [1], loss: 0.000000, acc: 1.00%, avg_loss: 3289141.065568, avg_acc: 73.21%
2017-12-20 20:03:00.919208: Iter: 78000 [1], loss: 0.000000, acc: 1.00%, avg_loss: 3277384.184396, avg_acc: 73.16%
2017-12-20 20:04:18.765090: Iter: 80000 [1], loss: 0.000000, acc: 1.00%, avg_loss: 3245690.676577, avg_acc: 73.30%
2017-12-20 20:05:37.389892: Iter: 82000 [1], loss: 0.000000, acc: 1.00%, avg_loss: 3223827.824679, avg_acc: 73.43%
2017-12-20 20:06:54.993768: Iter: 84000 [1], loss: 0.000000, acc: 1.00%, avg_loss: 3218534.086142, avg_acc: 73.39%
2017-12-20 20:08:12.486380: Iter: 86000 [1], loss: 0.000000, acc: 1.00%, avg_loss: 3201404.878984, avg_acc: 73.44%
2017-12-20 20:09:30.835196: Iter: 88000 [1], loss: 4578310.000000, acc: 0.00%, avg_loss: 3189161.306441, avg_acc: 73.46%
2017-12-20 20:10:49.641139: Iter: 90000 [1], loss: 0.000000, acc: 1.00%, avg_loss: 3174779.275333, avg_acc: 73.44%
2017-12-20 20:12:08.031483: Iter: 92000 [1], loss: 0.000000, acc: 1.00%, avg_loss: 3155611.585079, avg_acc: 73.51%
2017-12-20 20:13:25.260499: Iter: 94000 [1], loss: 0.000000, acc: 1.00%, avg_loss: 3147061.216500, avg_acc: 73.54%
2017-12-20 20:14:44.489615: Iter: 96000 [1], loss: 0.000000, acc: 1.00%, avg_loss: 3138540.553655, avg_acc: 73.46%
2017-12-20 20:16:02.881998: Iter: 98000 [1], loss: 0.000000, acc: 1.00%, avg_loss: 3119716.934602, avg_acc: 73.48%
2017-12-20 20:17:25.148150: Iter: 100000 [1], loss: 0.000000, acc: 1.00%, avg_loss: 3107645.258478, avg_acc: 73.52%
2017-12-20 20:18:59.754578: Iter: 102000 [1], loss: 0.000000, acc: 1.00%, avg_loss: 3103273.385510, avg_acc: 73.49%
2017-12-20 20:20:20.783907: Iter: 104000 [1], loss: 0.000000, acc: 1.00%, avg_loss: 3093404.021850, avg_acc: 73.49%
2017-12-20 20:21:39.435577: Iter: 106000 [1], loss: 0.000000, acc: 1.00%, avg_loss: 3086164.053279, avg_acc: 73.43%
2017-12-20 20:22:58.694580: Iter: 108000 [1], loss: 3020526.000000, acc: 0.00%, avg_loss: 3080666.275000, avg_acc: 73.38%
2017-12-20 20:22:58.695121: 
Epoch 1: avg_Loss: 3080723.325431952253, avg_Acc: 73.380988536825
2017-12-20 20:22:58.695152: Learning rates changed LR: 1.000000 
2017-12-20 20:24:18.393068: Iter: 110000 [2], loss: 0.000000, acc: 1.00%, avg_loss: 1938583.224750, avg_acc: 79.35%
2017-12-20 20:25:38.121198: Iter: 112000 [2], loss: 229808.000000, acc: 0.00%, avg_loss: 1982275.389375, avg_acc: 79.00%
2017-12-20 20:26:56.903110: Iter: 114000 [2], loss: 5171302.000000, acc: 0.00%, avg_loss: 1972004.848000, avg_acc: 79.20%
2017-12-20 20:28:22.684620: Iter: 116000 [2], loss: 0.000000, acc: 1.00%, avg_loss: 1935068.978438, avg_acc: 79.31%
2017-12-20 20:30:01.976947: Iter: 118000 [2], loss: 0.000000, acc: 1.00%, avg_loss: 1910097.437800, avg_acc: 79.47%
2017-12-20 20:31:19.812023: Iter: 120000 [2], loss: 0.000000, acc: 1.00%, avg_loss: 1902761.583417, avg_acc: 79.36%
2017-12-20 20:32:37.862072: Iter: 122000 [2], loss: 0.000000, acc: 1.00%, avg_loss: 1883058.633679, avg_acc: 79.34%
2017-12-20 20:33:56.288485: Iter: 124000 [2], loss: 0.000000, acc: 1.00%, avg_loss: 1863676.004844, avg_acc: 79.35%
2017-12-20 20:35:13.546453: Iter: 126000 [2], loss: 12809756.000000, acc: 0.00%, avg_loss: 1843227.788694, avg_acc: 79.52%
2017-12-20 20:36:30.483468: Iter: 128000 [2], loss: 0.000000, acc: 1.00%, avg_loss: 1857728.737275, avg_acc: 79.55%
2017-12-20 20:37:47.480204: Iter: 130000 [2], loss: 9737890.000000, acc: 0.00%, avg_loss: 1848745.978761, avg_acc: 79.48%
2017-12-20 20:39:05.612127: Iter: 132000 [2], loss: 0.000000, acc: 1.00%, avg_loss: 1847898.502427, avg_acc: 79.52%
2017-12-20 20:40:24.374306: Iter: 134000 [2], loss: 0.000000, acc: 1.00%, avg_loss: 1855991.001731, avg_acc: 79.47%
2017-12-20 20:41:47.790761: Iter: 136000 [2], loss: 0.000000, acc: 1.00%, avg_loss: 1835357.958875, avg_acc: 79.61%
2017-12-20 20:43:08.449337: Iter: 138000 [2], loss: 27830594.000000, acc: 0.00%, avg_loss: 1835769.671033, avg_acc: 79.64%
2017-12-20 20:44:30.192832: Iter: 140000 [2], loss: 0.000000, acc: 1.00%, avg_loss: 1844532.765156, avg_acc: 79.62%
2017-12-20 20:45:49.641872: Iter: 142000 [2], loss: 0.000000, acc: 1.00%, avg_loss: 1848743.966375, avg_acc: 79.53%
2017-12-20 20:47:07.169761: Iter: 144000 [2], loss: 0.000000, acc: 1.00%, avg_loss: 1847784.597396, avg_acc: 79.51%
2017-12-20 20:48:40.151395: Iter: 146000 [2], loss: 1517484.000000, acc: 0.00%, avg_loss: 1838373.306849, avg_acc: 79.54%
2017-12-20 20:50:09.856505: Iter: 148000 [2], loss: 0.000000, acc: 1.00%, avg_loss: 1840129.062069, avg_acc: 79.53%
2017-12-20 20:51:34.453497: Iter: 150000 [2], loss: 0.000000, acc: 1.00%, avg_loss: 1830665.594720, avg_acc: 79.61%
2017-12-20 20:52:52.923765: Iter: 152000 [2], loss: 0.000000, acc: 1.00%, avg_loss: 1833303.671244, avg_acc: 79.62%
2017-12-20 20:54:11.106853: Iter: 154000 [2], loss: 0.000000, acc: 1.00%, avg_loss: 1826767.177060, avg_acc: 79.70%
2017-12-20 20:55:31.253282: Iter: 156000 [2], loss: 0.000000, acc: 1.00%, avg_loss: 1819774.250307, avg_acc: 79.76%
2017-12-20 20:56:48.966077: Iter: 158000 [2], loss: 163742.000000, acc: 0.00%, avg_loss: 1821249.284335, avg_acc: 79.70%
2017-12-20 20:58:05.906978: Iter: 160000 [2], loss: 0.000000, acc: 1.00%, avg_loss: 1824916.366255, avg_acc: 79.65%
2017-12-20 20:59:23.090673: Iter: 162000 [2], loss: 0.000000, acc: 1.00%, avg_loss: 1825181.474769, avg_acc: 79.67%
2017-12-20 20:59:23.091220: 
Epoch 2: avg_Loss: 1825215.275051389821, avg_Acc: 79.669993888776
2017-12-20 20:59:23.091256: Learning rates changed LR: 1.000000 
2017-12-20 21:00:54.241651: Iter: 164000 [3], loss: 0.000000, acc: 1.00%, avg_loss: 1878937.430500, avg_acc: 78.00%
2017-12-20 21:02:47.630369: Iter: 166000 [3], loss: 0.000000, acc: 1.00%, avg_loss: 1912259.168750, avg_acc: 78.97%
2017-12-20 21:04:09.237852: Iter: 168000 [3], loss: 0.000000, acc: 1.00%, avg_loss: 1818144.544500, avg_acc: 79.38%
2017-12-20 21:05:29.156924: Iter: 170000 [3], loss: 0.000000, acc: 1.00%, avg_loss: 1837648.106375, avg_acc: 79.30%
2017-12-20 21:06:45.712475: Iter: 172000 [3], loss: 4213436.000000, acc: 0.00%, avg_loss: 1834437.711175, avg_acc: 79.23%
2017-12-20 21:08:07.063470: Iter: 174000 [3], loss: 0.000000, acc: 1.00%, avg_loss: 1843686.934063, avg_acc: 79.26%
2017-12-20 21:09:23.379199: Iter: 176000 [3], loss: 0.000000, acc: 1.00%, avg_loss: 1852180.796018, avg_acc: 79.35%
2017-12-20 21:10:39.800060: Iter: 178000 [3], loss: 0.000000, acc: 1.00%, avg_loss: 1844287.100391, avg_acc: 79.47%
2017-12-20 21:11:56.321655: Iter: 180000 [3], loss: 2491697.000000, acc: 0.00%, avg_loss: 1836102.495042, avg_acc: 79.63%
2017-12-20 21:13:13.444362: Iter: 182000 [3], loss: 9849761.000000, acc: 0.00%, avg_loss: 1837954.266362, avg_acc: 79.62%
2017-12-20 21:14:30.654649: Iter: 184000 [3], loss: 0.000000, acc: 1.00%, avg_loss: 1840000.770489, avg_acc: 79.64%
2017-12-20 21:15:47.832141: Iter: 186000 [3], loss: 0.000000, acc: 1.00%, avg_loss: 1851213.217792, avg_acc: 79.46%
2017-12-20 21:17:04.844441: Iter: 188000 [3], loss: 0.000000, acc: 1.00%, avg_loss: 1860450.938096, avg_acc: 79.34%
2017-12-20 21:18:22.114689: Iter: 190000 [3], loss: 0.000000, acc: 1.00%, avg_loss: 1856395.544250, avg_acc: 79.39%
2017-12-20 21:19:39.455384: Iter: 192000 [3], loss: 0.000000, acc: 1.00%, avg_loss: 1842400.225775, avg_acc: 79.36%
2017-12-20 21:20:56.692865: Iter: 194000 [3], loss: 1614366.500000, acc: 0.00%, avg_loss: 1834188.657805, avg_acc: 79.39%
2017-12-20 21:22:15.425825: Iter: 196000 [3], loss: 0.000000, acc: 1.00%, avg_loss: 1830167.898169, avg_acc: 79.41%
2017-12-20 21:23:33.817475: Iter: 198000 [3], loss: 0.000000, acc: 1.00%, avg_loss: 1823263.502799, avg_acc: 79.51%
2017-12-20 21:24:52.781059: Iter: 200000 [3], loss: 3482438.000000, acc: 0.00%, avg_loss: 1816025.379178, avg_acc: 79.57%
2017-12-20 21:26:10.213897: Iter: 202000 [3], loss: 0.000000, acc: 1.00%, avg_loss: 1807610.913225, avg_acc: 79.61%
2017-12-20 21:27:27.533583: Iter: 204000 [3], loss: 4163947.000000, acc: 0.00%, avg_loss: 1809337.252607, avg_acc: 79.59%
2017-12-20 21:28:45.013294: Iter: 206000 [3], loss: 14372311.000000, acc: 0.00%, avg_loss: 1813467.421489, avg_acc: 79.52%
2017-12-20 21:30:02.539753: Iter: 208000 [3], loss: 0.000000, acc: 1.00%, avg_loss: 1802740.562565, avg_acc: 79.61%
2017-12-20 21:31:20.055503: Iter: 210000 [3], loss: 0.000000, acc: 1.00%, avg_loss: 1809529.751313, avg_acc: 79.58%
2017-12-20 21:32:37.570906: Iter: 212000 [3], loss: 0.000000, acc: 1.00%, avg_loss: 1801872.938870, avg_acc: 79.61%
2017-12-20 21:33:55.019203: Iter: 214000 [3], loss: 25157780.000000, acc: 0.00%, avg_loss: 1799839.888875, avg_acc: 79.63%
2017-12-20 21:35:11.940281: Iter: 216000 [3], loss: 0.000000, acc: 1.00%, avg_loss: 1792651.486583, avg_acc: 79.68%
2017-12-20 21:35:11.940945: 
Epoch 3: avg_Loss: 1792684.684447860112, avg_Acc: 79.681105205652
2017-12-20 21:35:11.940990: Learning rates changed LR: 0.100000 
2017-12-20 21:36:36.389947: Iter: 218000 [4], loss: 30282540.000000, acc: 0.00%, avg_loss: 1790537.304500, avg_acc: 80.00%
2017-12-20 21:37:54.103759: Iter: 220000 [4], loss: 0.000000, acc: 1.00%, avg_loss: 1705259.990750, avg_acc: 80.47%
2017-12-20 21:39:12.323116: Iter: 222000 [4], loss: 0.000000, acc: 1.00%, avg_loss: 1643028.132250, avg_acc: 80.78%
2017-12-20 21:40:30.256354: Iter: 224000 [4], loss: 0.000000, acc: 1.00%, avg_loss: 1655952.508313, avg_acc: 80.86%
2017-12-20 21:41:48.023059: Iter: 226000 [4], loss: 0.000000, acc: 1.00%, avg_loss: 1677845.679000, avg_acc: 80.87%
2017-12-20 21:43:05.536114: Iter: 228000 [4], loss: 0.000000, acc: 1.00%, avg_loss: 1691589.568500, avg_acc: 80.77%
2017-12-20 21:44:23.742454: Iter: 230000 [4], loss: 0.000000, acc: 1.00%, avg_loss: 1710921.147643, avg_acc: 80.74%
2017-12-20 21:45:41.739596: Iter: 232000 [4], loss: 0.000000, acc: 1.00%, avg_loss: 1702906.210312, avg_acc: 80.64%
2017-12-20 21:46:59.794134: Iter: 234000 [4], loss: 0.000000, acc: 1.00%, avg_loss: 1702533.694750, avg_acc: 80.59%
2017-12-20 21:48:17.825264: Iter: 236000 [4], loss: 0.000000, acc: 1.00%, avg_loss: 1712701.361350, avg_acc: 80.46%
2017-12-20 21:49:35.837371: Iter: 238000 [4], loss: 0.000000, acc: 1.00%, avg_loss: 1716729.502989, avg_acc: 80.47%
2017-12-20 21:50:54.631927: Iter: 240000 [4], loss: 0.000000, acc: 1.00%, avg_loss: 1733161.682698, avg_acc: 80.37%
2017-12-20 21:52:11.794787: Iter: 242000 [4], loss: 836740.000000, acc: 0.00%, avg_loss: 1739106.535837, avg_acc: 80.27%
2017-12-20 21:53:28.597187: Iter: 244000 [4], loss: 0.000000, acc: 1.00%, avg_loss: 1733557.920330, avg_acc: 80.21%
2017-12-20 21:54:45.671058: Iter: 246000 [4], loss: 4162766.000000, acc: 0.00%, avg_loss: 1745118.102292, avg_acc: 80.16%
2017-12-20 21:56:02.932388: Iter: 248000 [4], loss: 0.000000, acc: 1.00%, avg_loss: 1741892.323305, avg_acc: 80.12%
2017-12-20 21:57:20.394849: Iter: 250000 [4], loss: 12299486.000000, acc: 0.00%, avg_loss: 1739630.638566, avg_acc: 80.10%
2017-12-20 21:58:38.521335: Iter: 252000 [4], loss: 0.000000, acc: 1.00%, avg_loss: 1751955.099826, avg_acc: 80.03%
2017-12-20 21:59:55.370970: Iter: 254000 [4], loss: 0.000000, acc: 1.00%, avg_loss: 1747821.874954, avg_acc: 80.03%
2017-12-20 22:01:12.205974: Iter: 256000 [4], loss: 19591870.000000, acc: 0.00%, avg_loss: 1754389.960381, avg_acc: 80.00%
2017-12-20 22:02:28.978288: Iter: 258000 [4], loss: 0.000000, acc: 1.00%, avg_loss: 1750277.872815, avg_acc: 80.04%
2017-12-20 22:03:45.930316: Iter: 260000 [4], loss: 6550682.000000, acc: 0.00%, avg_loss: 1753342.735040, avg_acc: 80.04%
2017-12-20 22:05:03.118042: Iter: 262000 [4], loss: 12110636.000000, acc: 0.00%, avg_loss: 1756313.218821, avg_acc: 79.99%
2017-12-20 22:06:19.848272: Iter: 264000 [4], loss: 0.000000, acc: 1.00%, avg_loss: 1759322.192276, avg_acc: 79.94%
2017-12-20 22:07:36.803142: Iter: 266000 [4], loss: 6862927.500000, acc: 0.00%, avg_loss: 1762172.486255, avg_acc: 79.90%
2017-12-20 22:08:53.973814: Iter: 268000 [4], loss: 0.000000, acc: 1.00%, avg_loss: 1761220.505063, avg_acc: 79.89%
2017-12-20 22:10:11.027386: Iter: 270000 [4], loss: 0.000000, acc: 1.00%, avg_loss: 1758648.709671, avg_acc: 79.85%
2017-12-20 22:10:11.028022: 
Epoch 4: avg_Loss: 1758681.277843108168, avg_Acc: 79.855182503380
2017-12-20 22:10:11.028057: Learning rates changed LR: 0.010000 
2017-12-20 22:11:28.582842: Iter: 272000 [5], loss: 0.000000, acc: 1.00%, avg_loss: 1791703.327000, avg_acc: 80.10%
2017-12-20 22:12:45.343161: Iter: 274000 [5], loss: 0.000000, acc: 1.00%, avg_loss: 1833258.699375, avg_acc: 79.90%
2017-12-20 22:14:02.636591: Iter: 276000 [5], loss: 0.000000, acc: 1.00%, avg_loss: 1792689.254833, avg_acc: 80.03%
2017-12-20 22:15:19.813761: Iter: 278000 [5], loss: 0.000000, acc: 1.00%, avg_loss: 1759641.806188, avg_acc: 80.26%
2017-12-20 22:16:36.817589: Iter: 280000 [5], loss: 0.000000, acc: 1.00%, avg_loss: 1724129.940500, avg_acc: 80.27%
2017-12-20 22:17:54.047492: Iter: 282000 [5], loss: 0.000000, acc: 1.00%, avg_loss: 1725983.949167, avg_acc: 80.21%
2017-12-20 22:19:11.617755: Iter: 284000 [5], loss: 0.000000, acc: 1.00%, avg_loss: 1728812.469643, avg_acc: 80.19%
2017-12-20 22:20:29.144901: Iter: 286000 [5], loss: 0.000000, acc: 1.00%, avg_loss: 1725875.050438, avg_acc: 80.32%
2017-12-20 22:21:46.645043: Iter: 288000 [5], loss: 0.000000, acc: 1.00%, avg_loss: 1738415.848417, avg_acc: 80.22%
2017-12-20 22:23:04.120759: Iter: 290000 [5], loss: 0.000000, acc: 1.00%, avg_loss: 1722201.656150, avg_acc: 80.33%
2017-12-20 22:24:21.556618: Iter: 292000 [5], loss: 0.000000, acc: 1.00%, avg_loss: 1738851.805511, avg_acc: 80.29%
2017-12-20 22:25:39.108265: Iter: 294000 [5], loss: 0.000000, acc: 1.00%, avg_loss: 1735915.230906, avg_acc: 80.23%
2017-12-20 22:26:56.532043: Iter: 296000 [5], loss: 0.000000, acc: 1.00%, avg_loss: 1733834.701587, avg_acc: 80.20%
2017-12-20 22:28:14.015262: Iter: 298000 [5], loss: 0.000000, acc: 1.00%, avg_loss: 1736555.894170, avg_acc: 80.20%
2017-12-20 22:29:31.062463: Iter: 300000 [5], loss: 927917.000000, acc: 0.00%, avg_loss: 1747678.344267, avg_acc: 80.13%
2017-12-20 22:30:48.155185: Iter: 302000 [5], loss: 0.000000, acc: 1.00%, avg_loss: 1750845.331828, avg_acc: 80.04%
2017-12-20 22:32:05.145515: Iter: 304000 [5], loss: 0.000000, acc: 1.00%, avg_loss: 1748901.692529, avg_acc: 79.98%
2017-12-20 22:33:22.318930: Iter: 306000 [5], loss: 0.000000, acc: 1.00%, avg_loss: 1755485.749819, avg_acc: 79.95%
2017-12-20 22:34:39.527097: Iter: 308000 [5], loss: 0.000000, acc: 1.00%, avg_loss: 1750529.880447, avg_acc: 79.99%
2017-12-20 22:35:56.317654: Iter: 310000 [5], loss: 0.000000, acc: 1.00%, avg_loss: 1746599.792075, avg_acc: 80.06%
2017-12-20 22:37:13.220189: Iter: 312000 [5], loss: 8944033.000000, acc: 0.00%, avg_loss: 1756597.283512, avg_acc: 79.99%
2017-12-20 22:38:30.491058: Iter: 314000 [5], loss: 0.000000, acc: 1.00%, avg_loss: 1758318.057455, avg_acc: 79.96%
2017-12-20 22:39:47.421607: Iter: 316000 [5], loss: 20663246.000000, acc: 0.00%, avg_loss: 1764963.777739, avg_acc: 79.89%
2017-12-20 22:41:04.295316: Iter: 318000 [5], loss: 0.000000, acc: 1.00%, avg_loss: 1747969.930333, avg_acc: 79.97%
2017-12-20 22:42:21.288957: Iter: 320000 [5], loss: 0.000000, acc: 1.00%, avg_loss: 1759082.385630, avg_acc: 79.91%
2017-12-20 22:43:38.246415: Iter: 322000 [5], loss: 26235494.000000, acc: 0.00%, avg_loss: 1755003.086183, avg_acc: 79.93%
2017-12-20 22:44:55.223417: Iter: 324000 [5], loss: 0.000000, acc: 1.00%, avg_loss: 1752180.911704, avg_acc: 79.93%
2017-12-20 22:44:55.224095: 
Epoch 5: avg_Loss: 1752213.360099263256, avg_Acc: 79.932961721513
2017-12-20 22:44:55.224130: Learning rates changed LR: 0.001000 
2017-12-20 22:46:12.858937: Iter: 326000 [6], loss: 0.000000, acc: 1.00%, avg_loss: 1637296.723250, avg_acc: 80.45%
2017-12-20 22:47:29.756391: Iter: 328000 [6], loss: 0.000000, acc: 1.00%, avg_loss: 1678476.636000, avg_acc: 81.08%
2017-12-20 22:48:46.579616: Iter: 330000 [6], loss: 0.000000, acc: 1.00%, avg_loss: 1685558.543667, avg_acc: 81.15%
2017-12-20 22:50:04.019751: Iter: 332000 [6], loss: 0.000000, acc: 1.00%, avg_loss: 1728658.093812, avg_acc: 80.75%
2017-12-20 22:51:21.665947: Iter: 334000 [6], loss: 0.000000, acc: 1.00%, avg_loss: 1735036.554650, avg_acc: 80.40%
2017-12-20 22:52:39.040610: Iter: 336000 [6], loss: 0.000000, acc: 1.00%, avg_loss: 1731424.088375, avg_acc: 80.33%
2017-12-20 22:53:56.105170: Iter: 338000 [6], loss: 0.000000, acc: 1.00%, avg_loss: 1738094.683250, avg_acc: 80.41%
2017-12-20 22:55:13.164895: Iter: 340000 [6], loss: 0.000000, acc: 1.00%, avg_loss: 1727432.734781, avg_acc: 80.39%
2017-12-20 22:56:30.278501: Iter: 342000 [6], loss: 0.000000, acc: 1.00%, avg_loss: 1741027.653167, avg_acc: 80.17%
2017-12-20 22:57:47.624647: Iter: 344000 [6], loss: 0.000000, acc: 1.00%, avg_loss: 1753638.395425, avg_acc: 80.12%
2017-12-20 22:59:04.850902: Iter: 346000 [6], loss: 0.000000, acc: 1.00%, avg_loss: 1749290.501909, avg_acc: 80.09%
2017-12-20 23:00:21.896885: Iter: 348000 [6], loss: 0.000000, acc: 1.00%, avg_loss: 1741433.286771, avg_acc: 80.14%
2017-12-20 23:01:38.942653: Iter: 350000 [6], loss: 0.000000, acc: 1.00%, avg_loss: 1751679.721942, avg_acc: 80.11%
2017-12-20 23:02:56.023149: Iter: 352000 [6], loss: 0.000000, acc: 1.00%, avg_loss: 1728754.918821, avg_acc: 80.20%
2017-12-20 23:04:13.678818: Iter: 354000 [6], loss: 8693596.000000, acc: 0.00%, avg_loss: 1738358.349433, avg_acc: 80.15%
2017-12-20 23:05:31.407187: Iter: 356000 [6], loss: 0.000000, acc: 1.00%, avg_loss: 1726815.464859, avg_acc: 80.27%
2017-12-20 23:06:48.781400: Iter: 358000 [6], loss: 0.000000, acc: 1.00%, avg_loss: 1735179.078882, avg_acc: 80.20%
2017-12-20 23:08:06.297537: Iter: 360000 [6], loss: 0.000000, acc: 1.00%, avg_loss: 1728948.003903, avg_acc: 80.23%
2017-12-20 23:09:23.956466: Iter: 362000 [6], loss: 8901014.000000, acc: 0.00%, avg_loss: 1734917.185461, avg_acc: 80.19%
2017-12-20 23:10:41.616079: Iter: 364000 [6], loss: 0.000000, acc: 1.00%, avg_loss: 1733824.036362, avg_acc: 80.16%
2017-12-20 23:11:59.309786: Iter: 366000 [6], loss: 0.000000, acc: 1.00%, avg_loss: 1731492.656345, avg_acc: 80.11%
2017-12-20 23:13:16.816949: Iter: 368000 [6], loss: 0.000000, acc: 1.00%, avg_loss: 1737889.375062, avg_acc: 80.09%
2017-12-20 23:14:34.133501: Iter: 370000 [6], loss: 0.000000, acc: 1.00%, avg_loss: 1749375.344277, avg_acc: 79.99%
2017-12-20 23:15:51.799249: Iter: 372000 [6], loss: 29046572.000000, acc: 0.00%, avg_loss: 1746780.069474, avg_acc: 79.99%
2017-12-20 23:17:09.331227: Iter: 374000 [6], loss: 7809486.000000, acc: 0.00%, avg_loss: 1748334.756215, avg_acc: 79.96%
2017-12-20 23:18:26.890168: Iter: 376000 [6], loss: 0.000000, acc: 1.00%, avg_loss: 1748247.438774, avg_acc: 80.00%
2017-12-20 23:19:44.214013: Iter: 378000 [6], loss: 2786834.000000, acc: 0.00%, avg_loss: 1751322.364968, avg_acc: 79.96%
2017-12-20 23:19:44.214548: 
Epoch 6: avg_Loss: 1751354.797463841969, avg_Acc: 79.964443785996
2017-12-20 23:19:44.214578: Learning rates changed LR: 0.000100 
2017-12-20 23:21:02.294881: Iter: 380000 [7], loss: 0.000000, acc: 1.00%, avg_loss: 1643377.561500, avg_acc: 80.90%
2017-12-20 23:22:19.510039: Iter: 382000 [7], loss: 0.000000, acc: 1.00%, avg_loss: 1701228.680000, avg_acc: 80.55%
2017-12-20 23:23:36.886205: Iter: 384000 [7], loss: 0.000000, acc: 1.00%, avg_loss: 1748940.245833, avg_acc: 80.13%
2017-12-20 23:24:53.673976: Iter: 386000 [7], loss: 0.000000, acc: 1.00%, avg_loss: 1754512.479625, avg_acc: 80.30%
2017-12-20 23:26:10.957098: Iter: 388000 [7], loss: 0.000000, acc: 1.00%, avg_loss: 1738734.125625, avg_acc: 80.33%
2017-12-20 23:27:28.338199: Iter: 390000 [7], loss: 0.000000, acc: 1.00%, avg_loss: 1749486.803688, avg_acc: 80.17%
2017-12-20 23:28:45.499310: Iter: 392000 [7], loss: 0.000000, acc: 1.00%, avg_loss: 1756562.729250, avg_acc: 80.09%
2017-12-20 23:30:02.805748: Iter: 394000 [7], loss: 139528.000000, acc: 0.00%, avg_loss: 1749375.035625, avg_acc: 79.97%
2017-12-20 23:31:20.198843: Iter: 396000 [7], loss: 0.000000, acc: 1.00%, avg_loss: 1725050.331361, avg_acc: 80.16%
2017-12-20 23:32:37.834129: Iter: 398000 [7], loss: 0.000000, acc: 1.00%, avg_loss: 1740258.428775, avg_acc: 80.11%
2017-12-20 23:33:55.366615: Iter: 400000 [7], loss: 0.000000, acc: 1.00%, avg_loss: 1756419.562182, avg_acc: 79.99%
2017-12-20 23:35:12.824066: Iter: 402000 [7], loss: 0.000000, acc: 1.00%, avg_loss: 1753787.669583, avg_acc: 80.04%
2017-12-20 23:36:30.347265: Iter: 404000 [7], loss: 0.000000, acc: 1.00%, avg_loss: 1761358.073288, avg_acc: 80.07%
2017-12-20 23:37:48.057687: Iter: 406000 [7], loss: 0.000000, acc: 1.00%, avg_loss: 1751147.889304, avg_acc: 80.14%
2017-12-20 23:39:05.582027: Iter: 408000 [7], loss: 0.000000, acc: 1.00%, avg_loss: 1737834.781158, avg_acc: 80.19%
2017-12-20 23:40:23.187612: Iter: 410000 [7], loss: 0.000000, acc: 1.00%, avg_loss: 1731668.084977, avg_acc: 80.24%
2017-12-20 23:41:40.479129: Iter: 412000 [7], loss: 0.000000, acc: 1.00%, avg_loss: 1730948.870787, avg_acc: 80.20%
2017-12-20 23:42:59.309733: Iter: 414000 [7], loss: 0.000000, acc: 1.00%, avg_loss: 1745979.664326, avg_acc: 80.10%
2017-12-20 23:44:18.006204: Iter: 416000 [7], loss: 0.000000, acc: 1.00%, avg_loss: 1753469.403454, avg_acc: 80.01%
2017-12-20 23:45:35.424810: Iter: 418000 [7], loss: 0.000000, acc: 1.00%, avg_loss: 1753339.074231, avg_acc: 79.98%
2017-12-20 23:46:52.890791: Iter: 420000 [7], loss: 0.000000, acc: 1.00%, avg_loss: 1767902.798351, avg_acc: 79.90%
2017-12-20 23:48:10.006583: Iter: 422000 [7], loss: 0.000000, acc: 1.00%, avg_loss: 1765996.166403, avg_acc: 79.94%
2017-12-20 23:49:27.123294: Iter: 424000 [7], loss: 0.000000, acc: 1.00%, avg_loss: 1759482.730147, avg_acc: 80.00%
2017-12-20 23:50:44.352465: Iter: 426000 [7], loss: 0.000000, acc: 1.00%, avg_loss: 1761136.474891, avg_acc: 79.92%
2017-12-20 23:52:01.708845: Iter: 428000 [7], loss: 0.000000, acc: 1.00%, avg_loss: 1761469.074575, avg_acc: 79.92%
2017-12-20 23:53:19.144807: Iter: 430000 [7], loss: 16581760.000000, acc: 0.00%, avg_loss: 1754476.270264, avg_acc: 79.97%
2017-12-20 23:54:36.570594: Iter: 432000 [7], loss: 0.000000, acc: 1.00%, avg_loss: 1751275.757023, avg_acc: 79.96%
2017-12-20 23:54:36.571241: 
Epoch 7: avg_Loss: 1751308.188656271435, avg_Acc: 79.962591899850
2017-12-20 23:54:36.571274: Learning rates changed LR: 0.000000 
2017-12-20 23:54:37.461413: 
Testing at last epoch...
2017-12-21 00:01:02.124797: epoch: 8 Accuracy: 81.0900%, loss: 1638658.733350000111, i: 10000
2017-12-21 00:01:02.124861: Exiting train...
