2017-12-20 12:14:22.284280: softmax classifer
2017-12-20 12:14:22.284337: Learning rates LR: 10.000000 
2017-12-20 12:15:54.872364: Iter: 2000 [0], loss: 2750804.250000, acc: 0.00%, avg_loss: 1196066.054463, avg_acc: 30.20%
2017-12-20 12:17:30.116134: Iter: 4000 [0], loss: 3346378.250000, acc: 0.00%, avg_loss: 1128245.323482, avg_acc: 34.08%
2017-12-20 12:18:59.934603: Iter: 6000 [0], loss: 0.000000, acc: 1.00%, avg_loss: 1116851.771608, avg_acc: 36.38%
2017-12-20 12:20:26.480689: Iter: 8000 [0], loss: 0.000000, acc: 1.00%, avg_loss: 1068469.561991, avg_acc: 38.90%
2017-12-20 12:21:54.096507: Iter: 10000 [0], loss: 3937051.750000, acc: 0.00%, avg_loss: 1050730.065124, avg_acc: 40.76%
2017-12-20 12:23:19.395438: Iter: 12000 [0], loss: 0.000000, acc: 1.00%, avg_loss: 1023892.911171, avg_acc: 42.58%
2017-12-20 12:23:19.395923: 
Epoch 0: avg_Loss: 1023978.242691204068, avg_Acc: 42.586882240187
2017-12-20 12:23:19.395967: Learning rates changed LR: 10.000000 
2017-12-20 12:24:53.047838: Iter: 14000 [1], loss: 0.000000, acc: 1.00%, avg_loss: 889167.634250, avg_acc: 49.60%
2017-12-20 12:26:26.928120: Iter: 16000 [1], loss: 0.000000, acc: 1.00%, avg_loss: 823720.152422, avg_acc: 52.48%
2017-12-20 12:27:49.689149: Iter: 18000 [1], loss: 201902.750000, acc: 0.00%, avg_loss: 802784.778927, avg_acc: 53.17%
2017-12-20 12:29:11.966595: Iter: 20000 [1], loss: 0.000000, acc: 1.00%, avg_loss: 800252.892484, avg_acc: 53.73%
2017-12-20 12:30:40.928715: Iter: 22000 [1], loss: 167458.250000, acc: 0.00%, avg_loss: 808415.579087, avg_acc: 53.94%
2017-12-20 12:32:14.554937: Iter: 24000 [1], loss: 3261795.250000, acc: 0.00%, avg_loss: 811182.068375, avg_acc: 54.27%
2017-12-20 12:32:14.555166: 
Epoch 1: avg_Loss: 811249.672514376231, avg_Acc: 54.271189265772
2017-12-20 12:32:14.555233: Learning rates changed LR: 10.000000 
2017-12-20 12:33:39.095428: Iter: 26000 [2], loss: 0.000000, acc: 1.00%, avg_loss: 760774.176594, avg_acc: 59.35%
2017-12-20 12:35:05.020170: Iter: 28000 [2], loss: 3125409.750000, acc: 0.00%, avg_loss: 769654.384000, avg_acc: 58.40%
2017-12-20 12:36:32.571871: Iter: 30000 [2], loss: 0.000000, acc: 1.00%, avg_loss: 788010.743760, avg_acc: 58.02%
2017-12-20 12:38:05.198419: Iter: 32000 [2], loss: 0.000000, acc: 1.00%, avg_loss: 781032.189977, avg_acc: 58.23%
2017-12-20 12:39:29.485833: Iter: 34000 [2], loss: 0.000000, acc: 1.00%, avg_loss: 795763.371325, avg_acc: 57.79%
2017-12-20 12:40:56.424158: Iter: 36000 [2], loss: 74058.750000, acc: 0.00%, avg_loss: 795284.140370, avg_acc: 57.97%
2017-12-20 12:40:56.424392: 
Epoch 2: avg_Loss: 795350.419571422623, avg_Acc: 57.971497624802
2017-12-20 12:40:56.424435: Learning rates changed LR: 10.000000 
2017-12-20 12:42:34.419172: Iter: 38000 [3], loss: 0.000000, acc: 1.00%, avg_loss: 744460.878063, avg_acc: 60.20%
2017-12-20 12:44:03.228944: Iter: 40000 [3], loss: 0.000000, acc: 1.00%, avg_loss: 747273.548422, avg_acc: 59.42%
2017-12-20 12:45:28.963272: Iter: 42000 [3], loss: 0.000000, acc: 1.00%, avg_loss: 764217.333313, avg_acc: 59.75%
2017-12-20 12:46:53.238395: Iter: 44000 [3], loss: 0.000000, acc: 1.00%, avg_loss: 757004.231977, avg_acc: 60.02%
2017-12-20 12:48:20.942882: Iter: 46000 [3], loss: 0.000000, acc: 1.00%, avg_loss: 754759.362906, avg_acc: 60.41%
2017-12-20 12:49:46.795447: Iter: 48000 [3], loss: 837893.750000, acc: 0.00%, avg_loss: 745544.118104, avg_acc: 60.71%
2017-12-20 12:49:46.795694: 
Epoch 3: avg_Loss: 745606.251958496519, avg_Acc: 60.713392782732
2017-12-20 12:49:46.795743: Learning rates changed LR: 10.000000 
2017-12-20 12:51:11.315939: Iter: 50000 [4], loss: 0.000000, acc: 1.00%, avg_loss: 714751.808156, avg_acc: 62.15%
2017-12-20 12:52:35.449900: Iter: 52000 [4], loss: 0.000000, acc: 1.00%, avg_loss: 719390.113906, avg_acc: 62.00%
2017-12-20 12:54:04.172389: Iter: 54000 [4], loss: 0.000000, acc: 1.00%, avg_loss: 704767.150490, avg_acc: 62.55%
2017-12-20 12:55:32.139910: Iter: 56000 [4], loss: 0.000000, acc: 1.00%, avg_loss: 707339.838039, avg_acc: 62.69%
2017-12-20 12:56:53.457932: Iter: 58000 [4], loss: 2590947.750000, acc: 0.00%, avg_loss: 717682.400000, avg_acc: 62.66%
2017-12-20 12:58:16.269074: Iter: 60000 [4], loss: 0.000000, acc: 1.00%, avg_loss: 714181.821198, avg_acc: 63.01%
2017-12-20 12:58:16.269356: 
Epoch 4: avg_Loss: 714241.341309692478, avg_Acc: 63.013584465372
2017-12-20 12:58:16.269408: Learning rates changed LR: 10.000000 
2017-12-20 12:59:53.600209: Iter: 62000 [5], loss: 0.000000, acc: 1.00%, avg_loss: 668200.343750, avg_acc: 64.30%
2017-12-20 13:01:16.402194: Iter: 64000 [5], loss: 0.000000, acc: 1.00%, avg_loss: 679406.055141, avg_acc: 63.98%
2017-12-20 13:02:36.670606: Iter: 66000 [5], loss: 2490846.500000, acc: 0.00%, avg_loss: 691817.781729, avg_acc: 63.47%
2017-12-20 13:03:57.690409: Iter: 68000 [5], loss: 2162474.000000, acc: 0.00%, avg_loss: 697119.293680, avg_acc: 63.41%
2017-12-20 13:05:23.823726: Iter: 70000 [5], loss: 0.000000, acc: 1.00%, avg_loss: 695871.912850, avg_acc: 63.67%
2017-12-20 13:07:10.892714: Iter: 72000 [5], loss: 0.000000, acc: 1.00%, avg_loss: 694703.867266, avg_acc: 63.85%
2017-12-20 13:07:10.893004: 
Epoch 5: avg_Loss: 694761.764079298242, avg_Acc: 63.855321276773
2017-12-20 13:07:10.893045: Learning rates changed LR: 10.000000 
2017-12-20 13:08:43.796640: Iter: 74000 [6], loss: 910819.750000, acc: 0.00%, avg_loss: 682484.206063, avg_acc: 65.30%
2017-12-20 13:10:07.717283: Iter: 76000 [6], loss: 134244.500000, acc: 0.00%, avg_loss: 686218.102453, avg_acc: 64.15%
2017-12-20 13:11:26.871587: Iter: 78000 [6], loss: 0.000000, acc: 1.00%, avg_loss: 703667.037208, avg_acc: 64.07%
2017-12-20 13:12:46.746781: Iter: 80000 [6], loss: 0.000000, acc: 1.00%, avg_loss: 692760.321930, avg_acc: 64.22%
2017-12-20 13:14:07.459489: Iter: 82000 [6], loss: 2426901.000000, acc: 0.00%, avg_loss: 693984.972319, avg_acc: 64.76%
2017-12-20 13:15:26.123473: Iter: 84000 [6], loss: 1682138.250000, acc: 0.00%, avg_loss: 695066.053724, avg_acc: 64.86%
2017-12-20 13:15:26.123670: 
Epoch 6: avg_Loss: 695123.980722351815, avg_Acc: 64.863738644887
2017-12-20 13:15:26.123697: Learning rates changed LR: 10.000000 
2017-12-20 13:16:53.071945: Iter: 86000 [7], loss: 1175057.625000, acc: 0.00%, avg_loss: 654538.541375, avg_acc: 65.80%
2017-12-20 13:18:10.564470: Iter: 88000 [7], loss: 339462.500000, acc: 0.00%, avg_loss: 683755.544719, avg_acc: 65.50%
2017-12-20 13:19:36.240355: Iter: 90000 [7], loss: 0.000000, acc: 1.00%, avg_loss: 702337.150688, avg_acc: 64.68%
2017-12-20 13:20:56.298121: Iter: 92000 [7], loss: 0.000000, acc: 1.00%, avg_loss: 705846.910836, avg_acc: 64.71%
2017-12-20 13:22:15.643765: Iter: 94000 [7], loss: 0.000000, acc: 1.00%, avg_loss: 703775.202019, avg_acc: 64.63%
2017-12-20 13:23:38.401789: Iter: 96000 [7], loss: 0.000000, acc: 1.00%, avg_loss: 691832.689630, avg_acc: 64.80%
2017-12-20 13:23:38.402024: 
Epoch 7: avg_Loss: 691890.347159138299, avg_Acc: 64.805400450037
2017-12-20 13:23:38.402061: Learning rates changed LR: 0.000000 
2017-12-20 13:23:39.191840: 
Testing at last epoch...
2017-12-20 13:30:43.287278: epoch: 8 Accuracy: 63.9500%, loss: 773703.887250000029, i: 10000
2017-12-20 13:30:43.287342: Exiting train...
