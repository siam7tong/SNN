2017-12-28 22:40:54.183699: softmax classifer
2017-12-28 22:40:54.183802: Learning rates LR: 0.001000 
2017-12-28 22:42:16.980488: Iter: 2000 [0], loss: 0.000000, acc: 1.00%, avg_loss: 260.205101, avg_acc: 76.80%
2017-12-28 22:43:36.113091: Iter: 4000 [0], loss: 0.000000, acc: 1.00%, avg_loss: 258.321195, avg_acc: 76.85%
2017-12-28 22:44:56.605949: Iter: 6000 [0], loss: 0.000000, acc: 1.00%, avg_loss: 259.348030, avg_acc: 76.75%
2017-12-28 22:46:20.384104: Iter: 8000 [0], loss: 0.000000, acc: 1.00%, avg_loss: 259.298877, avg_acc: 76.83%
2017-12-28 22:47:40.620003: Iter: 10000 [0], loss: 1202.075195, acc: 0.00%, avg_loss: 259.673350, avg_acc: 76.77%
2017-12-28 22:49:07.381232: Iter: 12000 [0], loss: 800.960449, acc: 0.00%, avg_loss: 256.565343, avg_acc: 77.03%
2017-12-28 22:49:07.381431: 
Epoch 0: avg_Loss: 256.586725186976, avg_Acc: 77.039753312776
2017-12-28 22:49:07.381465: Learning rates changed LR: 0.001000 
2017-12-28 22:50:30.966575: Iter: 14000 [1], loss: 127.829102, acc: 0.00%, avg_loss: 234.861460, avg_acc: 77.50%
2017-12-28 22:51:59.117721: Iter: 16000 [1], loss: 478.426270, acc: 0.00%, avg_loss: 245.711688, avg_acc: 77.65%
2017-12-28 22:54:03.749107: Iter: 18000 [1], loss: 0.000000, acc: 1.00%, avg_loss: 241.050727, avg_acc: 77.80%
2017-12-28 22:56:10.020691: Iter: 20000 [1], loss: 1751.910645, acc: 0.00%, avg_loss: 247.244426, avg_acc: 77.70%
2017-12-28 22:58:14.072255: Iter: 22000 [1], loss: 0.000000, acc: 1.00%, avg_loss: 246.299277, avg_acc: 77.64%
2017-12-28 23:00:20.653773: Iter: 24000 [1], loss: 0.000000, acc: 1.00%, avg_loss: 255.609748, avg_acc: 77.03%
2017-12-28 23:00:20.654034: 
Epoch 1: avg_Loss: 255.631050975805, avg_Acc: 77.031419284940
2017-12-28 23:00:20.654075: Learning rates changed LR: 0.000100 
2017-12-28 23:02:08.623167: Iter: 26000 [2], loss: 0.000000, acc: 1.00%, avg_loss: 263.380919, avg_acc: 77.85%
2017-12-28 23:04:14.641007: Iter: 28000 [2], loss: 0.000000, acc: 1.00%, avg_loss: 258.037970, avg_acc: 77.95%
2017-12-28 23:06:20.866689: Iter: 30000 [2], loss: 0.000000, acc: 1.00%, avg_loss: 254.344754, avg_acc: 77.63%
2017-12-28 23:08:28.945579: Iter: 32000 [2], loss: 0.000000, acc: 1.00%, avg_loss: 253.319021, avg_acc: 77.46%
2017-12-28 23:10:15.878027: Iter: 34000 [2], loss: 0.000000, acc: 1.00%, avg_loss: 254.456140, avg_acc: 77.35%
2017-12-28 23:11:42.450148: Iter: 36000 [2], loss: 0.000000, acc: 1.00%, avg_loss: 254.849585, avg_acc: 77.11%
2017-12-28 23:11:42.450335: 
Epoch 2: avg_Loss: 254.870824387086, avg_Acc: 77.114759563297
2017-12-28 23:11:42.450381: Learning rates changed LR: 0.000100 
2017-12-28 23:13:08.149084: Iter: 38000 [3], loss: 0.000000, acc: 1.00%, avg_loss: 243.347103, avg_acc: 78.55%
2017-12-28 23:14:31.806242: Iter: 40000 [3], loss: 0.000000, acc: 1.00%, avg_loss: 254.818883, avg_acc: 77.70%
2017-12-28 23:15:53.507836: Iter: 42000 [3], loss: 0.000000, acc: 1.00%, avg_loss: 251.464821, avg_acc: 77.78%
2017-12-28 23:17:14.183900: Iter: 44000 [3], loss: 0.000000, acc: 1.00%, avg_loss: 255.106932, avg_acc: 77.20%
2017-12-28 23:18:49.284253: Iter: 46000 [3], loss: 0.000000, acc: 1.00%, avg_loss: 251.981063, avg_acc: 77.31%
2017-12-28 23:20:56.411273: Iter: 48000 [3], loss: 0.000000, acc: 1.00%, avg_loss: 254.512644, avg_acc: 77.08%
2017-12-28 23:20:56.411514: 
Epoch 3: avg_Loss: 254.533855335587, avg_Acc: 77.081423451954
2017-12-28 23:20:56.411555: Learning rates changed LR: 0.000010 
2017-12-28 23:20:57.272893: 
Testing at last epoch...
2017-12-28 23:31:17.617199: epoch: 4 Accuracy: 77.3800%, loss: 238.302114370978, i: 10000
2017-12-28 23:31:17.617289: Exiting train...
